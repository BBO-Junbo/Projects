{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    def __init__(self):\n",
    "        self.string = \"\"\n",
    "        self.pointer = 0\n",
    "        self.keywords = {\n",
    "            \"int\": (5, \"-\"),\n",
    "            \"else\": (15, \"-\"),\n",
    "            \"if\": (17, \"-\"),\n",
    "            \"while\": (20, \"-\")\n",
    "        }\n",
    "\n",
    "        self.constants = {\n",
    "            \"整数\": (100, \"整数\")\n",
    "        }\n",
    "\n",
    "        self.operators = {\n",
    "            \"+\": (41, \"-\"),\n",
    "            \"-\": (42, \"-\"),\n",
    "            \"*\": (43, \"-\"),\n",
    "            \"/\": (44, \"-\"),\n",
    "            \"%\": (45, \"-\"),\n",
    "            \"=\": (46, \"-\"),\n",
    "            \">\": (47, \"-\"),\n",
    "            \">=\": (48, \"-\"),\n",
    "            \"<\": (49, \"-\"),\n",
    "            \"<=\": (50, \"-\"),\n",
    "            \"==\": (51, \"-\"),\n",
    "            \"!=\": (52, \"-\"),\n",
    "            \"&&\": (53, \"-\"),\n",
    "            \"||\": (54, \"-\"),\n",
    "            \"!\": (55, \"-\"),\n",
    "            \"++\": (56, \"-\"),\n",
    "            \"--\": (57, \"-\")\n",
    "        }\n",
    "\n",
    "        self.delimiters = {\n",
    "            \"(\": (81, \"-\"),\n",
    "            \")\": (82, \"-\"),\n",
    "            \",\": (83, \"-\"),\n",
    "            \";\": (84, \"-\"),\n",
    "            \"{\": (86, \"-\"),\n",
    "            \"}\": (87, \"-\"),\n",
    "            \"[\": (88, \"-\"),\n",
    "            \"]\": (89, \"-\")\n",
    "        }\n",
    "    def get_operator_symbol(self, op):\n",
    "        for symbol, (token_type, _) in self.operators.items():\n",
    "            if token_type == op:\n",
    "                return symbol\n",
    "        return None\n",
    "    def count_tokens(self):\n",
    "        tokens = []\n",
    "        current_token = \"\"\n",
    "        i = 0\n",
    "        while i < len(self.string):\n",
    "            if self.string[i].isdigit():  # Check if the character is a digit\n",
    "                current_token += self.string[i]\n",
    "                i += 1\n",
    "                while i < len(self.string) and self.string[i].isdigit():\n",
    "                    current_token += self.string[i]\n",
    "                    i += 1\n",
    "                tokens.append((100, current_token))  # Append the Integer constant with token type 100\n",
    "                current_token = \"\"\n",
    "            elif self.string[i].isalnum() or self.string[i] == '_':\n",
    "                current_token += self.string[i]\n",
    "                i += 1\n",
    "                while i < len(self.string) and (self.string[i].isalnum() or self.string[i] == '_'):\n",
    "                    current_token += self.string[i]\n",
    "                    i += 1\n",
    "                if current_token in self.keywords:\n",
    "                    tokens.append(self.keywords[current_token])\n",
    "                else:\n",
    "                    tokens.append(self.is_identifier(current_token))\n",
    "                current_token = \"\"\n",
    "            elif self.string[i] in self.operators or self.string[i:i+2] in self.operators:\n",
    "                if self.string[i:i+2] in self.operators:\n",
    "                    tokens.append(self.operators[self.string[i:i+2]])\n",
    "                    i += 2\n",
    "                else:\n",
    "                    tokens.append(self.operators[self.string[i]])\n",
    "                    i += 1\n",
    "            elif self.string[i] in self.delimiters:\n",
    "                tokens.append(self.delimiters[self.string[i]])\n",
    "                i += 1\n",
    "            elif self.string[i].isspace():\n",
    "                i += 1\n",
    "            else:\n",
    "                raise ValueError(\"Illegal character: {}\".format(self.string[i]))\n",
    "        return len(tokens)\n",
    "    \n",
    "    def is_identifier(self, token):\n",
    "        return 111, token\n",
    "\n",
    "    def get_next_token(self):\n",
    "        char = self.string[self.pointer]\n",
    "        token=\"\"\n",
    "        if char.isdigit():  # Check if the character is a digit\n",
    "            token = char\n",
    "            self.pointer += 1\n",
    "            while self.pointer < len(self.string) and self.string[self.pointer].isdigit():\n",
    "                token += self.string[self.pointer]\n",
    "                self.pointer += 1\n",
    "            return (100, token)  # Return the Integer constant with token type 100\n",
    "        elif char.isalnum() or char == '_':\n",
    "            token = char\n",
    "            self.pointer += 1\n",
    "            while self.pointer < len(self.string) and (self.string[self.pointer].isalnum() or self.string[self.pointer] == '_'):\n",
    "                token += self.string[self.pointer]\n",
    "                self.pointer += 1\n",
    "            if token in self.keywords:\n",
    "                return self.keywords[token]\n",
    "            else:\n",
    "                return self.is_identifier(token)\n",
    "        elif char in self.operators or (self.string[self.pointer:self.pointer + 2]) in self.operators:\n",
    "            if (self.string[self.pointer:self.pointer + 2]) in self.operators:\n",
    "                self.pointer += 2\n",
    "                return self.operators[self.string[self.pointer-2:self.pointer]]\n",
    "            else:\n",
    "                self.pointer += 1\n",
    "                return self.operators[char]\n",
    "        elif char in self.delimiters:\n",
    "            self.pointer += 1\n",
    "            return self.delimiters[char]\n",
    "        elif char.isspace():\n",
    "            self.pointer += 1\n",
    "            return self.get_next_token()\n",
    "\n",
    "    def analyze(self):\n",
    "        if self.pointer >= len(self.string):\n",
    "            return None\n",
    "        return self.get_next_token()\n",
    "\n",
    "    def analyze_file(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()  # Read file contents once\n",
    "                self.string = file_content  # Assign the content to self.string\n",
    "                self.token_num = self.count_tokens()\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) stmts ⟶ stmt rest0\n",
      "(2) stmt ⟶ loc = expr;\n",
      "(3) loc ⟶ id resta\n",
      "(4) resta ⟶ ℇ\n",
      "(5) expr ⟶ term rest5\n",
      "(6) term ⟶ unary rest6\n",
      "(7) unary ⟶ factor\n",
      "(8) factor ⟶ num\n",
      "(9) unary ⟶ factor\n",
      "(10) factor ⟶ loc\n",
      "(11) loc ⟶ id resta\n",
      "(12) resta ⟶ ℇ\n",
      "(13) rest6 ⟶ ℇ\n",
      "(14) term ⟶ unary rest6\n",
      "(15) unary ⟶ factor\n",
      "(16) factor ⟶ num\n",
      "(17) unary ⟶ factor\n",
      "(18) factor ⟶ loc\n",
      "(19) loc ⟶ id resta\n",
      "(20) resta ⟶ ℇ\n",
      "(21) rest6 ⟶ ℇ\n",
      "(22) term ⟶ unary rest6\n",
      "(23) unary ⟶ factor\n",
      "(24) factor ⟶ loc\n",
      "(25) loc ⟶ id resta\n",
      "(26) resta ⟶ ℇ\n",
      "(27) rest6 ⟶ ℇ\n",
      "(28) rest5 ⟶ ℇ\n",
      "(29) rest0 ⟶ ℇ\n",
      "0: ['/', '6', 'b', 't1']\n",
      "1: ['*', '5', 'c', 't2']\n",
      "2: ['+', 't1', 't2', 't3']\n",
      "3: ['-', 't3', 'd', 't4']\n",
      "4: ['=', 't4', '-', 'a']\n"
     ]
    }
   ],
   "source": [
    "class Parser:\n",
    "    def __init__(self, lexer):\n",
    "        self.lexer = lexer\n",
    "        self.current_token = None\n",
    "        self.step = 1\n",
    "        self.temp_count = 0\n",
    "        self.quadruples = []\n",
    "\n",
    "    def eat(self, token_type):\n",
    "        if self.current_token is not None and self.current_token[0] == token_type:\n",
    "            self.current_token = self.lexer.analyze()\n",
    "\n",
    "    def print_step(self, production):\n",
    "        print(f\"({self.step}) {production}\")\n",
    "        self.step += 1\n",
    "\n",
    "    def emit(self, op, arg1, arg2, result):\n",
    "        self.quadruples.append([op, arg1, arg2, result])\n",
    "\n",
    "    def newtemp(self):\n",
    "        self.temp_count += 1\n",
    "        return f\"t{self.temp_count}\"\n",
    "\n",
    "    def factor(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        token_type = self.current_token[0]\n",
    "        if token_type == 100:\n",
    "            self.print_step(\"factor ⟶ num\")\n",
    "            token_value = self.current_token[1]\n",
    "            self.eat(100)\n",
    "            return token_value\n",
    "        elif token_type == 111:\n",
    "            self.print_step(\"factor ⟶ loc\")\n",
    "            return self.loc()\n",
    "        elif token_type == 81:  # '('\n",
    "            self.print_step(\"factor ⟶ (expr)\")\n",
    "            self.eat(81)  # '('\n",
    "            result = self.expression()\n",
    "            self.eat(82)  # ')'\n",
    "            return result\n",
    "        return None\n",
    "\n",
    "    def loc(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"loc ⟶ id resta\")\n",
    "        id_value = self.current_token[1]\n",
    "        self.eat(111)  # Eat 'id'\n",
    "        self.resta()\n",
    "        return id_value\n",
    "\n",
    "    def resta(self):\n",
    "        if self.current_token is None:\n",
    "            self.print_step(\"resta ⟶ ℇ\")\n",
    "            return None\n",
    "        if self.current_token[0] == 88:  # '[' \n",
    "            self.print_step(\"resta ⟶ [elist]\")\n",
    "            self.eat(88)  # Eat '['\n",
    "            self.elist()\n",
    "            self.eat(89)  # Eat ']'\n",
    "        else:\n",
    "            self.print_step(\"resta ⟶ ℇ\")\n",
    "        return None\n",
    "\n",
    "    def elist(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"elist ⟶ expr rest1\")\n",
    "        self.expression()\n",
    "        self.rest1()\n",
    "        return None\n",
    "\n",
    "    def rest1(self):\n",
    "        if self.current_token is None:\n",
    "            self.print_step(\"rest1 ⟶ ℇ\")\n",
    "            return None\n",
    "        if self.current_token[0] == 83:  # ',' \n",
    "            self.print_step(\"rest1 ⟶ , expr rest1\")\n",
    "            self.eat(83)  # Eat ','\n",
    "            self.expression()\n",
    "            self.rest1()\n",
    "        else:\n",
    "            self.print_step(\"rest1 ⟶ ℇ\")\n",
    "        return None\n",
    "\n",
    "    def unary(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"unary ⟶ factor\")\n",
    "        return self.factor()\n",
    "\n",
    "    def term(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"term ⟶ unary rest6\")\n",
    "        left = self.unary()\n",
    "        while self.current_token is not None and self.current_token[0] in (43, 44):\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            right = self.unary()\n",
    "            temp = self.newtemp()\n",
    "            self.emit(self.lexer.get_operator_symbol(op), left, right, temp)\n",
    "            left = temp\n",
    "        self.print_step(\"rest6 ⟶ ℇ\")\n",
    "        return left\n",
    "\n",
    "    def expression(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"expr ⟶ term rest5\")\n",
    "        left = self.term()\n",
    "        while self.current_token is not None and self.current_token[0] in (41, 42):\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            right = self.term()\n",
    "            temp = self.newtemp()\n",
    "            self.emit(self.lexer.get_operator_symbol(op), left, right, temp)\n",
    "            left = temp\n",
    "        self.print_step(\"rest5 ⟶ ℇ\")\n",
    "        return left\n",
    "\n",
    "    def rop_expr(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        while self.current_token is not None and self.current_token[0] in (47, 48, 49, 50):\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            if op == 49:\n",
    "                self.print_step(\"rop_expr ⟶ < expr\")\n",
    "            elif op == 50:\n",
    "                self.print_step(\"rop_expr ⟶ <= expr\")\n",
    "            elif op == 47:\n",
    "                self.print_step(\"rop_expr ⟶ > expr\")\n",
    "            elif op == 48:\n",
    "                self.print_step(\"rop_expr ⟶ >= expr\")\n",
    "            result = self.expression()\n",
    "            return result\n",
    "        else:\n",
    "            self.print_step(\"rop_expr ⟶ ℇ\")\n",
    "            return None\n",
    "\n",
    "    def rel(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"rel ⟶ expr rop_expr\")\n",
    "        left = self.expression()\n",
    "        right = self.rop_expr()\n",
    "        return (left, right) if right else left\n",
    "\n",
    "    def equality(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"equality ⟶ rel rest4\")\n",
    "        left = self.rel()\n",
    "        while self.current_token is not None and self.current_token[0] in (51, 52):\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            if op == 51:\n",
    "                self.print_step(\"rest4 ⟶ == rel rest4\")\n",
    "            elif op == 52:\n",
    "                self.print_step(\"rest4 ⟶ != rel rest4\")\n",
    "            right = self.rel()\n",
    "            left = (left, op, right)\n",
    "        self.print_step(\"rest4 ⟶ ℇ\")\n",
    "        return left\n",
    "\n",
    "    def bool_expr(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"bool ⟶ equality\")\n",
    "        return self.equality()\n",
    "\n",
    "    def stmts(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"stmts ⟶ stmt rest0\")\n",
    "        self.stmt()\n",
    "        self.rest0()\n",
    "\n",
    "    def rest0(self):\n",
    "        if self.current_token is None:\n",
    "            self.print_step(\"rest0 ⟶ ℇ\")\n",
    "            return\n",
    "        if self.current_token[0] == 111 or self.current_token[0] == 17:  # 'if'\n",
    "            self.print_step(\"rest0 ⟶ stmt rest0\")\n",
    "            self.stmt()\n",
    "            self.rest0()\n",
    "        else:\n",
    "            self.print_step(\"rest0 ⟶ ℇ\")\n",
    "\n",
    "    def stmt(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        if self.current_token[0] == 111:  \n",
    "            self.print_step(\"stmt ⟶ loc = expr;\")\n",
    "            var_name = self.loc()\n",
    "            self.eat(46)  # Eat '='\n",
    "            expr_result = self.expression()\n",
    "            self.emit('=', expr_result, '-', var_name) \n",
    "            self.eat(84)  # Eat ';'\n",
    "        elif self.current_token[0] == 17:  # 'if'\n",
    "            self.print_step(\"stmt ⟶ if (bool) stmt else stmt\")\n",
    "            self.eat(17)  # Eat 'if'\n",
    "            self.eat(81)  # Eat '('\n",
    "            self.bool_expr()\n",
    "            self.eat(82)  # Eat ')'\n",
    "            self.stmt()\n",
    "            self.eat(15)  # Eat 'else'\n",
    "            self.stmt()\n",
    "        elif self.current_token[0] == 20:  # 'while'\n",
    "            self.print_step(\"stmt ⟶ while (bool) stmt\")\n",
    "            self.eat(20)  # Eat 'while'\n",
    "            self.eat(81)  # Eat '('\n",
    "            self.bool_expr()\n",
    "            self.eat(82)  # Eat ')'\n",
    "            self.stmt()\n",
    "\n",
    "    def parse(self):\n",
    "        self.current_token = self.lexer.analyze()\n",
    "        self.stmts()\n",
    "        return self.quadruples\n",
    "\n",
    "# Example usage:\n",
    "lexer = Lexer()  # 你需要实现或提供Lexer的实现\n",
    "lexer.analyze_file(\"source_code6.txt\")\n",
    "parser = Parser(lexer)\n",
    "quadruples = parser.parse()\n",
    "\n",
    "for idx, quad in enumerate(quadruples):\n",
    "    print(f\"{idx}: {quad}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aodprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
