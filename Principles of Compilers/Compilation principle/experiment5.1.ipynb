{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    def __init__(self):\n",
    "        self.string = \"\"\n",
    "        self.pointer = 0\n",
    "        self.keywords = {\n",
    "            \"int\": (5, \"-\"),\n",
    "            \"else\": (15, \"-\"),\n",
    "            \"if\": (17, \"-\"),\n",
    "            \"while\": (20, \"-\")\n",
    "        }\n",
    "\n",
    "        self.constants = {\n",
    "            \"整数\": (100, \"整数\")\n",
    "        }\n",
    "\n",
    "        self.operators = {\n",
    "            \"+\": (41, \"-\"),\n",
    "            \"-\": (42, \"-\"),\n",
    "            \"*\": (43, \"-\"),\n",
    "            \"/\": (44, \"-\"),\n",
    "            \"%\": (45, \"-\"),\n",
    "            \"=\": (46, \"-\"),\n",
    "            \">\": (47, \"-\"),\n",
    "            \">=\": (48, \"-\"),\n",
    "            \"<\": (49, \"-\"),\n",
    "            \"<=\": (50, \"-\"),\n",
    "            \"==\": (51, \"-\"),\n",
    "            \"!=\": (52, \"-\"),\n",
    "            \"&&\": (53, \"-\"),\n",
    "            \"||\": (54, \"-\"),\n",
    "            \"!\": (55, \"-\"),\n",
    "            \"++\": (56, \"-\"),\n",
    "            \"--\": (57, \"-\")\n",
    "        }\n",
    "\n",
    "        self.delimiters = {\n",
    "            \"(\": (81, \"-\"),\n",
    "            \")\": (82, \"-\"),\n",
    "            \",\": (83, \"-\"),\n",
    "            \";\": (84, \"-\"),\n",
    "            \"{\": (86, \"-\"),\n",
    "            \"}\": (87, \"-\"),\n",
    "            \"[\": (88, \"-\"),\n",
    "            \"]\": (89, \"-\")\n",
    "        }\n",
    "    def get_operator_symbol(self, op):\n",
    "        for symbol, (token_type, _) in self.operators.items():\n",
    "            if token_type == op:\n",
    "                return symbol\n",
    "        return None\n",
    "    def count_tokens(self):\n",
    "        tokens = []\n",
    "        current_token = \"\"\n",
    "        i = 0\n",
    "        while i < len(self.string):\n",
    "            if self.string[i].isdigit():  # Check if the character is a digit\n",
    "                current_token += self.string[i]\n",
    "                i += 1\n",
    "                while i < len(self.string) and self.string[i].isdigit():\n",
    "                    current_token += self.string[i]\n",
    "                    i += 1\n",
    "                tokens.append((100, current_token))  # Append the Integer constant with token type 100\n",
    "                current_token = \"\"\n",
    "            elif self.string[i].isalnum() or self.string[i] == '_':\n",
    "                current_token += self.string[i]\n",
    "                i += 1\n",
    "                while i < len(self.string) and (self.string[i].isalnum() or self.string[i] == '_'):\n",
    "                    current_token += self.string[i]\n",
    "                    i += 1\n",
    "                if current_token in self.keywords:\n",
    "                    tokens.append(self.keywords[current_token])\n",
    "                else:\n",
    "                    tokens.append(self.is_identifier(current_token))\n",
    "                current_token = \"\"\n",
    "            elif self.string[i] in self.operators or self.string[i:i+2] in self.operators:\n",
    "                if self.string[i:i+2] in self.operators:\n",
    "                    tokens.append(self.operators[self.string[i:i+2]])\n",
    "                    i += 2\n",
    "                else:\n",
    "                    tokens.append(self.operators[self.string[i]])\n",
    "                    i += 1\n",
    "            elif self.string[i] in self.delimiters:\n",
    "                tokens.append(self.delimiters[self.string[i]])\n",
    "                i += 1\n",
    "            elif self.string[i].isspace():\n",
    "                i += 1\n",
    "            else:\n",
    "                raise ValueError(\"Illegal character: {}\".format(self.string[i]))\n",
    "        return len(tokens)\n",
    "    \n",
    "    def is_identifier(self, token):\n",
    "        return 111, token\n",
    "\n",
    "    def get_next_token(self):\n",
    "        char = self.string[self.pointer]\n",
    "        token=\"\"\n",
    "        if char.isdigit():  # Check if the character is a digit\n",
    "            token = char\n",
    "            self.pointer += 1\n",
    "            while self.pointer < len(self.string) and self.string[self.pointer].isdigit():\n",
    "                token += self.string[self.pointer]\n",
    "                self.pointer += 1\n",
    "            return (100, token)  # Return the Integer constant with token type 100\n",
    "        elif char.isalnum() or char == '_':\n",
    "            token = char\n",
    "            self.pointer += 1\n",
    "            while self.pointer < len(self.string) and (self.string[self.pointer].isalnum() or self.string[self.pointer] == '_'):\n",
    "                token += self.string[self.pointer]\n",
    "                self.pointer += 1\n",
    "            if token in self.keywords:\n",
    "                return self.keywords[token]\n",
    "            else:\n",
    "                return self.is_identifier(token)\n",
    "        elif char in self.operators or (self.string[self.pointer:self.pointer + 2]) in self.operators:\n",
    "            if (self.string[self.pointer:self.pointer + 2]) in self.operators:\n",
    "                self.pointer += 2\n",
    "                return self.operators[self.string[self.pointer-2:self.pointer]]\n",
    "            else:\n",
    "                self.pointer += 1\n",
    "                return self.operators[char]\n",
    "        elif char in self.delimiters:\n",
    "            self.pointer += 1\n",
    "            return self.delimiters[char]\n",
    "        elif char.isspace():\n",
    "            self.pointer += 1\n",
    "            return self.get_next_token()\n",
    "\n",
    "    def analyze(self):\n",
    "        if self.pointer >= len(self.string):\n",
    "            return None\n",
    "        return self.get_next_token()\n",
    "\n",
    "    def analyze_file(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()  # Read file contents once\n",
    "                self.string = file_content  # Assign the content to self.string\n",
    "                self.token_num = self.count_tokens()\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) stmts ⟶ stmt rest0\n",
      "(2) stmt ⟶ while (bool) stmt\n",
      "(3) bool ⟶ equality\n",
      "(4) equality ⟶ rel rest4\n",
      "(5) rel ⟶ expr rop_expr\n",
      "(6) expr ⟶ term\n",
      "(7) term ⟶ factor\n",
      "(8) factor ⟶ loc\n",
      "(9) loc ⟶ id resta\n",
      "(10) resta ⟶ ℇ\n",
      "(11) rop_expr ⟶ rel_op expr\n",
      "(12) expr ⟶ term\n",
      "(13) term ⟶ factor\n",
      "(14) factor ⟶ loc\n",
      "(15) loc ⟶ id resta\n",
      "(16) resta ⟶ ℇ\n",
      "(17) rest4 ⟶ ℇ\n",
      "(18) stmt ⟶ if (bool) stmt else stmt\n",
      "(19) bool ⟶ equality\n",
      "(20) equality ⟶ rel rest4\n",
      "(21) rel ⟶ expr rop_expr\n",
      "(22) expr ⟶ term\n",
      "(23) term ⟶ factor\n",
      "(24) factor ⟶ loc\n",
      "(25) loc ⟶ id resta\n",
      "(26) resta ⟶ ℇ\n",
      "(27) rop_expr ⟶ ℇ\n",
      "(28) rest4 ⟶ ℇ\n",
      "(29) stmt ⟶ loc = expr;\n",
      "(30) loc ⟶ id resta\n",
      "(31) resta ⟶ ℇ\n",
      "(32) expr ⟶ term\n",
      "(33) term ⟶ factor\n",
      "(34) factor ⟶ loc\n",
      "(35) loc ⟶ id resta\n",
      "(36) resta ⟶ ℇ\n",
      "(37) term ⟶ factor\n",
      "(38) factor ⟶ loc\n",
      "(39) loc ⟶ id resta\n",
      "(40) resta ⟶ ℇ\n",
      "(41) stmt ⟶ loc = expr;\n",
      "(42) loc ⟶ id resta\n",
      "(43) resta ⟶ ℇ\n",
      "(44) expr ⟶ term\n",
      "(45) term ⟶ factor\n",
      "(46) factor ⟶ loc\n",
      "(47) loc ⟶ id resta\n",
      "(48) resta ⟶ ℇ\n",
      "(49) factor ⟶ loc\n",
      "(50) loc ⟶ id resta\n",
      "(51) resta ⟶ ℇ\n",
      "(52) rest0 ⟶ stmt rest0\n",
      "(53) stmt ⟶ loc = expr;\n",
      "(54) loc ⟶ id resta\n",
      "(55) resta ⟶ ℇ\n",
      "(56) expr ⟶ term\n",
      "(57) term ⟶ factor\n",
      "(58) factor ⟶ loc\n",
      "(59) loc ⟶ id resta\n",
      "(60) resta ⟶ ℇ\n",
      "(61) rest0 ⟶ ℇ\n",
      "0: ['j<', 'a', 'b', '-']\n",
      "1: ['j', '-', '-', '-']\n",
      "2: ['jnz', 'c', '-', '-']\n",
      "3: ['j', '-', '-', '-']\n",
      "4: ['+', 'y', 'z', 't1']\n",
      "5: ['=', 't1', '-', 'x']\n",
      "6: ['-', 'y', 'z', 't2']\n",
      "7: ['=', 't2', '-', 'x']\n",
      "8: ['=', 'y', '-', 'a']\n"
     ]
    }
   ],
   "source": [
    "class SymbolTableEntry:\n",
    "    def __init__(self, name, ndim=0, place=None, array=None, offset=None):\n",
    "        self.name = name          # 符号名\n",
    "        self.ndim = ndim          # 维数\n",
    "        self.place = place        # 简单名字或数组名字的地址\n",
    "        self.array = array        # 指向符号表中相应数组名字表项的指针\n",
    "        self.offset = offset      # 数组地址中变量部分\n",
    "        self.in_place = []        # 存放由 Elist 中的下标表达式计算出来的值\n",
    "\n",
    "    def set_dimensions(self, ndim):\n",
    "        self.ndim = ndim\n",
    "\n",
    "    def add_in_place(self, value):\n",
    "        self.in_place.append(value)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"SymbolTableEntry(name={self.name}, ndim={self.ndim}, place={self.place}, array={self.array}, offset={self.offset}, in_place={self.in_place})\"\n",
    "def makelist(nextquad):\n",
    "    return [nextquad]\n",
    "\n",
    "class SymbolTable:\n",
    "    def __init__(self):\n",
    "        self.table = {}\n",
    "\n",
    "    def add_entry(self, name, ndim=0, place=None, array=None, offset=None):\n",
    "        entry = SymbolTableEntry(name, ndim, place, array, offset)\n",
    "        self.table[name] = entry\n",
    "        return entry\n",
    "\n",
    "    def get_entry(self, name):\n",
    "        return self.table.get(name, None)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join(str(entry) for entry in self.table.values())\n",
    "\n",
    "\n",
    "class Parser:\n",
    "    def __init__(self, lexer):\n",
    "        self.lexer = lexer\n",
    "        self.current_token = None\n",
    "        self.step = 1\n",
    "        self.temp_count = 0\n",
    "        self.quadruples = []\n",
    "        self.symbol_table = SymbolTable()\n",
    "        self.quad_index = 0  # 初始化四元组索引\n",
    "\n",
    "    def nextquad(self):\n",
    "        current_quad = self.quad_index\n",
    "        self.quad_index += 1\n",
    "        return current_quad\n",
    "\n",
    "    def makelist(self, index):\n",
    "        return [index]\n",
    "\n",
    "    def backpatch(self, list_, target):\n",
    "        for index in list_:\n",
    "            self.quadruples[index][-1] = target\n",
    "\n",
    "    def eat(self, token_type):\n",
    "        if self.current_token is not None and self.current_token[0] == token_type:\n",
    "            self.current_token = self.lexer.analyze()\n",
    "\n",
    "    def print_step(self, production):\n",
    "        print(f\"({self.step}) {production}\")\n",
    "        self.step += 1\n",
    "\n",
    "    def emit(self, op, arg1, arg2, result):\n",
    "        self.quadruples.append([op, arg1, arg2, result])\n",
    "\n",
    "    def newtemp(self):\n",
    "        self.temp_count += 1\n",
    "        return f\"t{self.temp_count}\"\n",
    "\n",
    "    def factor(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        token_type = self.current_token[0]\n",
    "        if token_type == 100:\n",
    "            self.print_step(\"factor ⟶ num\")\n",
    "            token_value = self.current_token[1]\n",
    "            self.eat(100)\n",
    "            return token_value\n",
    "        elif token_type == 111:\n",
    "            self.print_step(\"factor ⟶ loc\")\n",
    "            loc_place, loc_offset = self.loc()\n",
    "            if loc_offset is None:\n",
    "                return loc_place\n",
    "            else:\n",
    "                factor_place = self.newtemp()\n",
    "                self.emit('=[]', f\"{loc_place}[{loc_offset}]\", '-', factor_place)\n",
    "                return factor_place\n",
    "        elif token_type == 81:  # '('\n",
    "            self.print_step(\"factor ⟶ (expr)\")\n",
    "            self.eat(81)  # '('\n",
    "            result = self.expression()\n",
    "            self.eat(82)  # ')'\n",
    "            return result\n",
    "        else:\n",
    "            raise SyntaxError(f\"Unexpected token: {self.current_token}\")\n",
    "\n",
    "    def loc(self):\n",
    "        if self.current_token is None:\n",
    "            return None, None\n",
    "        self.print_step(\"loc ⟶ id resta\")\n",
    "        id_value = self.current_token[1]\n",
    "        self.eat(111)  # Eat 'id'\n",
    "        entry = self.symbol_table.get_entry(id_value)\n",
    "        if entry is None:\n",
    "            entry = self.symbol_table.add_entry(id_value)\n",
    "        inArray = id_value\n",
    "        place, offset = self.resta(inArray)\n",
    "        entry.place = place\n",
    "        entry.offset = offset\n",
    "        return place, offset\n",
    "\n",
    "    def resta(self, inArray):\n",
    "        if self.current_token is None:\n",
    "            self.print_step(\"resta ⟶ ℇ\")\n",
    "            return inArray, None\n",
    "        if self.current_token[0] == 88:  \n",
    "            self.print_step(\"resta ⟶ [elist]\")\n",
    "            self.eat(88)  # Eat '['\n",
    "            array = self.symbol_table.get_entry(inArray)\n",
    "            array.place = inArray\n",
    "            self.elist(array)\n",
    "            self.eat(89)  # Eat ']'\n",
    "            place = self.newtemp()\n",
    "            self.emit('-', array.place, 'C', place)\n",
    "            offset = self.newtemp()\n",
    "            self.emit('*', array.offset, 'w', offset)\n",
    "            return place, offset\n",
    "        else:\n",
    "            self.print_step(\"resta ⟶ ℇ\")\n",
    "            return inArray, None\n",
    "\n",
    "    def elist(self, array):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"elist ⟶ expr rest1\")\n",
    "        expr_place = self.expression()\n",
    "        array.add_in_place(expr_place)\n",
    "        rest1_inPlace = expr_place\n",
    "        rest1_inNdim = 1\n",
    "        array.offset = self.rest1(array, rest1_inNdim, rest1_inPlace)\n",
    "        return None\n",
    "\n",
    "    def rest1(self, array, inNdim, inPlace):\n",
    "        if self.current_token is None:\n",
    "            self.print_step(\"rest1 ⟶ ℇ\")\n",
    "            return inPlace\n",
    "        if self.current_token[0] == 83:  \n",
    "            self.print_step(\"rest1 ⟶ , expr rest11\")\n",
    "            self.eat(83)  # Eat ','\n",
    "            expr_place = self.expression()\n",
    "            t = self.newtemp()\n",
    "            m = inNdim + 1\n",
    "            self.emit('*', inPlace, f\"n{m}\", t)\n",
    "            self.emit('+', t, expr_place, t)\n",
    "            rest11_inPlace = t\n",
    "            rest11_inNdim = m\n",
    "            return self.rest1(array, rest11_inNdim, rest11_inPlace)\n",
    "        else:\n",
    "            self.print_step(\"rest1 ⟶ ℇ\")\n",
    "            return inPlace\n",
    "\n",
    "    def term(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"term ⟶ factor\")\n",
    "        left = self.factor()\n",
    "        while self.current_token is not None and self.current_token[0] in (42, 47):  # '*' or '/'\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            right = self.factor()\n",
    "            temp = self.newtemp()\n",
    "            self.emit(self.lexer.get_operator_symbol(op), left, right, temp)\n",
    "            left = temp\n",
    "        return left\n",
    "\n",
    "    def expression(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"expr ⟶ term\")\n",
    "        left = self.term()\n",
    "        while self.current_token is not None and self.current_token[0] in (41, 42):  # '+' or '-'\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            right = self.term()\n",
    "            temp = self.newtemp()\n",
    "            self.emit(self.lexer.get_operator_symbol(op), left, right, temp)\n",
    "            left = temp\n",
    "        return left\n",
    "\n",
    "    def bool_expr(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"bool ⟶ equality\")\n",
    "        equality_truelist, equality_falselist = self.equality()\n",
    "        bool_truelist = equality_truelist\n",
    "        bool_falselist = equality_falselist\n",
    "        return bool_truelist, bool_falselist\n",
    "\n",
    "    def equality(self):\n",
    "        if self.current_token is None:\n",
    "            return None, None\n",
    "        self.print_step(\"equality ⟶ rel rest4\")\n",
    "        rel_truelist, rel_falselist = self.rel()\n",
    "        rest4_truelist, rest4_falselist = self.rest4(rel_truelist, rel_falselist)\n",
    "        equality_truelist = rest4_truelist\n",
    "        equality_falselist = rest4_falselist\n",
    "        return equality_truelist, equality_falselist\n",
    "\n",
    "    def rel(self):\n",
    "        if self.current_token is None:\n",
    "            return None, None\n",
    "        self.print_step(\"rel ⟶ expr rop_expr\")\n",
    "        expr_place = self.expression()\n",
    "        rop_expr_inPlace = expr_place\n",
    "        rop_expr_truelist, rop_expr_falselist = self.rop_expr(rop_expr_inPlace)\n",
    "        rel_truelist = rop_expr_truelist\n",
    "        rel_falselist = rop_expr_falselist\n",
    "        return rel_truelist, rel_falselist\n",
    "\n",
    "    def rop_expr(self, inPlace):\n",
    "            if self.current_token is None:\n",
    "                return None, None\n",
    "            if self.current_token[0] in (47, 48, 49, 50):  \n",
    "                self.print_step(\"rop_expr ⟶ rel_op expr\")\n",
    "                rel_op = self.current_token[0]\n",
    "                self.eat(rel_op)\n",
    "                expr_place = self.expression()\n",
    "                nextquad = self.nextquad()  # 获取当前四元组索引\n",
    "                truelist = self.makelist(nextquad)\n",
    "                nextquad_plus_one = self.nextquad()  # 获取下一个四元组索引\n",
    "                falselist = self.makelist(nextquad_plus_one)\n",
    "                self.emit(f'j{self.lexer.get_operator_symbol(rel_op)}', inPlace, expr_place, '-')\n",
    "                self.emit('j', '-', '-', '-')\n",
    "                return truelist, falselist\n",
    "            elif self.current_token[0] == 82:  # ℇ\n",
    "                self.print_step(\"rop_expr ⟶ ℇ\")\n",
    "                nextquad = self.nextquad()  # 获取当前四元组索引\n",
    "                truelist = self.makelist(nextquad)\n",
    "                nextquad_plus_one = self.nextquad()  # 获取下一个四元组索引\n",
    "                falselist = self.makelist(nextquad_plus_one)\n",
    "                self.emit('jnz', inPlace, '-', '-')\n",
    "                self.emit('j', '-', '-', '-')\n",
    "                return truelist, falselist\n",
    "            else:\n",
    "                raise SyntaxError(f\"Unexpected token: {self.current_token}\")\n",
    "\n",
    "\n",
    "    def rest4(self, inTruelist, inFalselist):\n",
    "        if self.current_token is None:\n",
    "            return None, None\n",
    "        if self.current_token[0] in (46, 47):  # '==', '!='\n",
    "            self.print_step(\"rest4 ⟶ == rel rest41 | != rel rest41\")\n",
    "            rel_truelist, rel_falselist = self.rel()\n",
    "            rest41_inTruelist = rel_truelist\n",
    "            rest41_inFalselist = rel_falselist\n",
    "            truelist = rest41_inTruelist\n",
    "            falselist = rest41_inFalselist\n",
    "            return truelist, falselist\n",
    "        elif self.current_token[0] == 82:  # ℇ\n",
    "            self.print_step(\"rest4 ⟶ ℇ\")\n",
    "            truelist = inTruelist\n",
    "            falselist = inFalselist\n",
    "            return truelist, falselist\n",
    "        else:\n",
    "            raise SyntaxError(f\"Unexpected token: {self.current_token}\")\n",
    "\n",
    "    def stmts(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"stmts ⟶ stmt rest0\")\n",
    "        self.stmt()\n",
    "        self.rest0()\n",
    "\n",
    "    def stmt(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        if self.current_token[0] == 111:  # identifier\n",
    "            self.print_step(\"stmt ⟶ loc = expr;\")\n",
    "            loc_place, loc_offset = self.loc()\n",
    "            self.eat(46)  # '='\n",
    "            expr_place = self.expression()\n",
    "            if loc_offset is None:\n",
    "                self.emit('=', expr_place, '-', loc_place)\n",
    "            else:\n",
    "                self.emit('[]=', expr_place, '-', f\"{loc_place}[{loc_offset}]\")\n",
    "            self.eat(84)  # ';'\n",
    "        elif self.current_token[0] == 17:  # Check if token type is 'if'\n",
    "            self.print_step(\"stmt ⟶ if (bool) stmt else stmt\")\n",
    "            self.eat(17)  # Eat 'if'\n",
    "            self.eat(81)  # Eat '('\n",
    "            self.bool_expr()\n",
    "            self.eat(82)  # Eat ')'\n",
    "            self.stmt()\n",
    "            self.eat(15)  # Eat 'else'\n",
    "            self.stmt()\n",
    "        elif self.current_token[0] == 20:  # Check if token type is 'while'\n",
    "            self.print_step(\"stmt ⟶ while (bool) stmt\")\n",
    "            self.eat(20)  # Eat 'while'\n",
    "            self.eat(81)  # Eat '('\n",
    "            self.bool_expr()\n",
    "            self.eat(82)  # Eat ')'\n",
    "            self.stmt()\n",
    "        else:\n",
    "            raise SyntaxError(f\"Unexpected token: {self.current_token}\")\n",
    "\n",
    "    def rest0(self):\n",
    "        if self.current_token is None:\n",
    "            self.print_step(\"rest0 ⟶ ℇ\")\n",
    "            return\n",
    "        if self.current_token[0] == 111 or self.current_token[0] == 17:  # identifier or 'if'\n",
    "            self.print_step(\"rest0 ⟶ stmt rest0\")\n",
    "            self.stmt()\n",
    "            self.rest0()\n",
    "        else:\n",
    "            self.print_step(\"rest0 ⟶ ℇ\")\n",
    "    def parse(self):\n",
    "        self.current_token = self.lexer.analyze()\n",
    "        self.stmts()\n",
    "        return self.quadruples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lexer = Lexer()  # 你需要实现或提供Lexer的实现\n",
    "lexer.analyze_file(\"source_code8.txt\")\n",
    "parser = Parser(lexer)\n",
    "quadruples = parser.parse()\n",
    "\n",
    "for idx, quad in enumerate(quadruples):\n",
    "    print(f\"{idx}: {quad}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aodprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
