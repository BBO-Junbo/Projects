{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    def __init__(self):\n",
    "        self.string = \"\"\n",
    "        self.pointer = 0\n",
    "        self.keywords = {\n",
    "            \"int\": (5, \"-\"),\n",
    "            \"else\": (15, \"-\"),\n",
    "            \"if\": (17, \"-\"),\n",
    "            \"while\": (20, \"-\")\n",
    "        }\n",
    "\n",
    "        self.constants = {\n",
    "            \"整数\": (100, \"整数\")\n",
    "        }\n",
    "\n",
    "        self.operators = {\n",
    "            \"+\": (41, \"-\"),\n",
    "            \"-\": (42, \"-\"),\n",
    "            \"*\": (43, \"-\"),\n",
    "            \"/\": (44, \"-\"),\n",
    "            \"%\": (45, \"-\"),\n",
    "            \"=\": (46, \"-\"),\n",
    "            \">\": (47, \"-\"),\n",
    "            \">=\": (48, \"-\"),\n",
    "            \"<\": (49, \"-\"),\n",
    "            \"<=\": (50, \"-\"),\n",
    "            \"==\": (51, \"-\"),\n",
    "            \"!=\": (52, \"-\"),\n",
    "            \"&&\": (53, \"-\"),\n",
    "            \"||\": (54, \"-\"),\n",
    "            \"!\": (55, \"-\"),\n",
    "            \"++\": (56, \"-\"),\n",
    "            \"--\": (57, \"-\")\n",
    "        }\n",
    "\n",
    "        self.delimiters = {\n",
    "            \"(\": (81, \"-\"),\n",
    "            \")\": (82, \"-\"),\n",
    "            \",\": (83, \"-\"),\n",
    "            \";\": (84, \"-\"),\n",
    "            \"{\": (86, \"-\"),\n",
    "            \"}\": (87, \"-\"),\n",
    "            \"[\": (88, \"-\"),\n",
    "            \"]\": (89, \"-\")\n",
    "        }\n",
    "        \n",
    "    def count_tokens(self):\n",
    "        tokens = []\n",
    "        current_token = \"\"\n",
    "        i = 0\n",
    "        while i < len(self.string):\n",
    "            if self.string[i].isdigit():  # Check if the character is a digit\n",
    "                current_token += self.string[i]\n",
    "                i += 1\n",
    "                while i < len(self.string) and self.string[i].isdigit():\n",
    "                    current_token += self.string[i]\n",
    "                    i += 1\n",
    "                tokens.append((100, current_token))  # Append the Integer constant with token type 100\n",
    "                current_token = \"\"\n",
    "            elif self.string[i].isalnum() or self.string[i] == '_':\n",
    "                current_token += self.string[i]\n",
    "                i += 1\n",
    "                while i < len(self.string) and (self.string[i].isalnum() or self.string[i] == '_'):\n",
    "                    current_token += self.string[i]\n",
    "                    i += 1\n",
    "                if current_token in self.keywords:\n",
    "                    tokens.append(self.keywords[current_token])\n",
    "                else:\n",
    "                    tokens.append(self.is_identifier(current_token))\n",
    "                current_token = \"\"\n",
    "            elif self.string[i] in self.operators or self.string[i:i+2] in self.operators:\n",
    "                if self.string[i:i+2] in self.operators:\n",
    "                    tokens.append(self.operators[self.string[i:i+2]])\n",
    "                    i += 2\n",
    "                else:\n",
    "                    tokens.append(self.operators[self.string[i]])\n",
    "                    i += 1\n",
    "            elif self.string[i] in self.delimiters:\n",
    "                tokens.append(self.delimiters[self.string[i]])\n",
    "                i += 1\n",
    "            elif self.string[i].isspace():\n",
    "                i += 1\n",
    "            else:\n",
    "                raise ValueError(\"Illegal character: {}\".format(self.string[i]))\n",
    "        return len(tokens)\n",
    "    \n",
    "    def is_identifier(self, token):\n",
    "        return 111, token\n",
    "\n",
    "    def get_next_token(self):\n",
    "        char = self.string[self.pointer]\n",
    "        token=\"\"\n",
    "        if char.isdigit():  # Check if the character is a digit\n",
    "            token = char\n",
    "            self.pointer += 1\n",
    "            while self.pointer < len(self.string) and self.string[self.pointer].isdigit():\n",
    "                token += self.string[self.pointer]\n",
    "                self.pointer += 1\n",
    "            return (100, token)  # Return the Integer constant with token type 100\n",
    "        elif char.isalnum() or char == '_':\n",
    "            token = char\n",
    "            self.pointer += 1\n",
    "            while self.pointer < len(self.string) and (self.string[self.pointer].isalnum() or self.string[self.pointer] == '_'):\n",
    "                token += self.string[self.pointer]\n",
    "                self.pointer += 1\n",
    "            if token in self.keywords:\n",
    "                return self.keywords[token]\n",
    "            else:\n",
    "                return self.is_identifier(token)\n",
    "        elif char in self.operators or (self.string[self.pointer:self.pointer + 2]) in self.operators:\n",
    "            if (self.string[self.pointer:self.pointer + 2]) in self.operators:\n",
    "                self.pointer += 2\n",
    "                return self.operators[self.string[self.pointer-2:self.pointer]]\n",
    "            else:\n",
    "                self.pointer += 1\n",
    "                return self.operators[char]\n",
    "        elif char in self.delimiters:\n",
    "            self.pointer += 1\n",
    "            return self.delimiters[char]\n",
    "        elif char.isspace():\n",
    "            self.pointer += 1\n",
    "            return self.get_next_token()\n",
    "\n",
    "    def analyze(self):\n",
    "        if self.pointer >= len(self.string):\n",
    "            return None\n",
    "        return self.get_next_token()\n",
    "\n",
    "    def analyze_file(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()  # Read file contents once\n",
    "                self.string = file_content  # Assign the content to self.string\n",
    "                self.token_num = self.count_tokens()\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, lexer):\n",
    "        self.lexer = lexer\n",
    "        self.current_token = None\n",
    "        self.step = 1\n",
    "\n",
    "    def eat(self, token_type):\n",
    "        if self.current_token is not None and self.current_token[0] == token_type:\n",
    "            self.current_token = self.lexer.analyze()\n",
    "\n",
    "    def print_step(self, production):\n",
    "        print(f\"({self.step}) {production}\")\n",
    "        self.step += 1\n",
    "\n",
    "    def factor(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        token_type = self.current_token[0]\n",
    "        if token_type == 100:\n",
    "            self.print_step(\"factor ⟶ num\")\n",
    "            token_value = self.current_token[1]\n",
    "            self.eat(100)\n",
    "            return int(token_value)\n",
    "        elif token_type == 111:\n",
    "            self.print_step(\"factor ⟶ loc\")\n",
    "            return self.loc()\n",
    "        elif token_type == 81:  # '('\n",
    "            self.print_step(\"factor ⟶ (expr)\")\n",
    "            self.eat(81)  # '('\n",
    "            result = self.expression()\n",
    "            self.eat(82)  # ')'\n",
    "            return result\n",
    "\n",
    "    def loc(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"loc ⟶ id resta\")\n",
    "        self.eat(111)  # Eat 'id'\n",
    "        self.resta()\n",
    "\n",
    "    def resta(self):\n",
    "        if self.current_token is None:\n",
    "            self.print_step(\"resta ⟶ ℇ\")\n",
    "            return\n",
    "        if self.current_token[0] == 88:  # '[' token type is 88\n",
    "            self.print_step(\"resta ⟶ [elist]\")\n",
    "            self.eat(88)  # Eat '['\n",
    "            self.elist()\n",
    "            self.eat(89)  # Eat ']'\n",
    "        else:\n",
    "            self.print_step(\"resta ⟶ ℇ\")\n",
    "\n",
    "    def elist(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"elist ⟶ expr rest1\")\n",
    "        self.expression()\n",
    "        self.rest1()\n",
    "\n",
    "    def rest1(self):\n",
    "        if self.current_token is None:\n",
    "            self.print_step(\"rest1 ⟶ ℇ\")\n",
    "            return\n",
    "        if self.current_token[0] == 83:  # ',' token type is 85\n",
    "            self.print_step(\"rest1 ⟶ , expr rest1\")\n",
    "            self.eat(83)  # Eat ','\n",
    "            self.expression()\n",
    "            self.rest1()\n",
    "        else:\n",
    "            self.print_step(\"rest1 ⟶ ℇ\")\n",
    "\n",
    "    def unary(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"unary ⟶ factor\")\n",
    "        return self.factor()\n",
    "\n",
    "    def term(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"term ⟶ unary rest6\")\n",
    "        result = self.unary()\n",
    "        while self.current_token is not None and self.current_token[0] in (43, 44):\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            if op == 43:\n",
    "                self.print_step(\"rest6 ⟶ * unary rest6\")\n",
    "                result *= self.unary()\n",
    "            elif op == 44:\n",
    "                self.print_step(\"rest6 ⟶ / unary rest6\")\n",
    "                result /= self.unary()\n",
    "        self.print_step(\"rest6 ⟶ ℇ\")\n",
    "        return result\n",
    "\n",
    "    def expression(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"expr ⟶ term rest5\")\n",
    "        result = self.term()\n",
    "        while self.current_token is not None and self.current_token[0] in (41, 42):\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            if op == 41:\n",
    "                self.print_step(\"rest5 ⟶ + term rest5\")\n",
    "                result += self.term()\n",
    "            elif op == 42:\n",
    "                self.print_step(\"rest5 ⟶ - term rest5\")\n",
    "                result -= self.term()\n",
    "        self.print_step(\"rest5 ⟶ ℇ\")\n",
    "        return result\n",
    "\n",
    "    def rop_expr(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        while self.current_token is not None and self.current_token[0] in (47, 48, 49, 50):\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            if op == 49:\n",
    "                self.print_step(\"rop_expr ⟶ < expr\")\n",
    "            elif op == 50:\n",
    "                self.print_step(\"rop_expr ⟶ <= expr\")\n",
    "            elif op == 47:\n",
    "                self.print_step(\"rop_expr ⟶ > expr\")\n",
    "            elif op == 48:\n",
    "                self.print_step(\"rop_expr ⟶ >= expr\")\n",
    "            result = self.expression()\n",
    "            return result\n",
    "        else:\n",
    "            self.print_step(\"rop_expr ⟶ ℇ\")\n",
    "            return None\n",
    "\n",
    "    def rel(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"rel ⟶ expr rop_expr\")\n",
    "        left = self.expression()\n",
    "        right = self.rop_expr()\n",
    "        if right is not None:\n",
    "            return left, right\n",
    "        return left\n",
    "\n",
    "    def equality(self):\n",
    "        if self.current_token is None:\n",
    "            return None\n",
    "        self.print_step(\"equality ⟶ rel rest4\")\n",
    "        left = self.rel()\n",
    "        while self.current_token is not None and self.current_token[0] in (51, 52):\n",
    "            op = self.current_token[0]\n",
    "            self.eat(op)\n",
    "            if op == 51:\n",
    "                self.print_step(\"rest4 ⟶ == rel rest4\")\n",
    "            elif op == 52:\n",
    "                self.print_step(\"rest4 ⟶ != rel rest4\")\n",
    "            right = self.rel()\n",
    "            left = (left, op, right)\n",
    "        self.print_step(\"rest4 ⟶ ℇ\")\n",
    "        return left\n",
    "\n",
    "    def bool_expr(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"bool ⟶ equality\")\n",
    "        return self.equality()\n",
    "\n",
    "    def stmts(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        self.print_step(\"stmts ⟶ stmt rest0\")\n",
    "        self.stmt()\n",
    "        self.rest0()\n",
    "\n",
    "    def rest0(self):\n",
    "        if self.current_token is None:\n",
    "            self.print_step(\"rest0 ⟶ ℇ\")\n",
    "            return\n",
    "        if self.current_token[0] == 111 or self.current_token[0] == 17:  # Check if token type is identifier or 'if'\n",
    "            self.print_step(\"rest0 ⟶ stmt rest0\")\n",
    "            self.stmt()\n",
    "            self.rest0()\n",
    "        else:\n",
    "            self.print_step(\"rest0 ⟶ ℇ\")\n",
    "\n",
    "    def stmt(self):\n",
    "        if self.current_token is None:\n",
    "            return\n",
    "        if self.current_token[0] == 111:  # Check if token type is identifier\n",
    "            self.print_step(\"stmt ⟶ loc = expr;\")\n",
    "            self.loc()\n",
    "            self.eat(46)  # Eat '='\n",
    "            self.expression()  # Corrected to expression instead of bool_expr\n",
    "            self.eat(84)  # Eat ';'\n",
    "        elif self.current_token[0] == 17:  # Check if token type is 'if'\n",
    "            self.print_step(\"stmt ⟶ if (bool) stmt else stmt\")\n",
    "            self.eat(17)  # Eat 'if'\n",
    "            self.eat(81)  # Eat '('\n",
    "            self.bool_expr()\n",
    "            self.eat(82)  # Eat ')'\n",
    "            self.stmt()\n",
    "            self.eat(15)  # Eat 'else'\n",
    "            self.stmt()\n",
    "        elif self.current_token[0] == 20:  # Check if token type is 'while'\n",
    "            self.print_step(\"stmt ⟶ while (bool) stmt\")\n",
    "            self.eat(20)  # Eat 'while'\n",
    "            self.eat(81)  # Eat '('\n",
    "            self.bool_expr()\n",
    "            self.eat(82)  # Eat ')'\n",
    "            self.stmt()\n",
    "\n",
    "    def parse(self):\n",
    "        self.current_token = self.lexer.analyze()\n",
    "        self.stmts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) stmts ⟶ stmt rest0\n",
      "(2) stmt ⟶ while (bool) stmt\n",
      "(3) bool ⟶ equality\n",
      "(4) equality ⟶ rel rest4\n",
      "(5) rel ⟶ expr rop_expr\n",
      "(6) expr ⟶ term rest5\n",
      "(7) term ⟶ unary rest6\n",
      "(8) unary ⟶ factor\n",
      "(9) factor ⟶ loc\n",
      "(10) loc ⟶ id resta\n",
      "(11) resta ⟶ [elist]\n",
      "(12) elist ⟶ expr rest1\n",
      "(13) expr ⟶ term rest5\n",
      "(14) term ⟶ unary rest6\n",
      "(15) unary ⟶ factor\n",
      "(16) factor ⟶ loc\n",
      "(17) loc ⟶ id resta\n",
      "(18) resta ⟶ ℇ\n",
      "(19) rest6 ⟶ ℇ\n",
      "(20) rest5 ⟶ ℇ\n",
      "(21) rest1 ⟶ ℇ\n",
      "(22) rest6 ⟶ ℇ\n",
      "(23) rest5 ⟶ ℇ\n",
      "(24) rop_expr ⟶ ℇ\n",
      "(25) rest4 ⟶ ℇ\n",
      "(26) stmt ⟶ loc = expr;\n",
      "(27) loc ⟶ id resta\n",
      "(28) resta ⟶ [elist]\n",
      "(29) elist ⟶ expr rest1\n",
      "(30) expr ⟶ term rest5\n",
      "(31) term ⟶ unary rest6\n",
      "(32) unary ⟶ factor\n",
      "(33) factor ⟶ loc\n",
      "(34) loc ⟶ id resta\n",
      "(35) resta ⟶ ℇ\n",
      "(36) rest6 ⟶ ℇ\n",
      "(37) rest5 ⟶ ℇ\n",
      "(38) rest1 ⟶ , expr rest1\n",
      "(39) expr ⟶ term rest5\n",
      "(40) term ⟶ unary rest6\n",
      "(41) unary ⟶ factor\n",
      "(42) factor ⟶ loc\n",
      "(43) loc ⟶ id resta\n",
      "(44) resta ⟶ ℇ\n",
      "(45) rest6 ⟶ ℇ\n",
      "(46) rest5 ⟶ ℇ\n",
      "(47) rest1 ⟶ ℇ\n",
      "(48) expr ⟶ term rest5\n",
      "(49) term ⟶ unary rest6\n",
      "(50) unary ⟶ factor\n",
      "(51) factor ⟶ num\n",
      "(52) rest6 ⟶ ℇ\n",
      "(53) rest5 ⟶ ℇ\n",
      "(54) rest0 ⟶ ℇ\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lexer =Lexer()\n",
    "lexer.analyze_file(\"source_code2.txt\")\n",
    "parser = Parser(lexer)\n",
    "result = parser.parse()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码有问题，没有得出期望的输出\n",
    "以下是一个正确的输入输出样例：\n",
    "测试文件中的内容：\n",
    "while(a[i]) \n",
    "    b[i,j]=10;\n",
    "输出：\n",
    "\n",
    "stmt ⟶ while(bool) stmt\n",
    "bool ⟶ equality\n",
    "equality ⟶rel rest4\n",
    "rel ⟶expr rop_expr\n",
    "expr ⟶ term rest5\n",
    "term ⟶ unary rest6\n",
    "unary ⟶factor\n",
    "factor ⟶ loc\n",
    "loc ⟶ id rest1\n",
    "rest1⟶[bool] rest1\n",
    "bool ⟶ equality\n",
    "equality ⟶rel rest4\n",
    "rel ⟶expr rop_expr\n",
    "expr ⟶ term rest5\n",
    "term ⟶ unary rest6\n",
    "unary ⟶factor\n",
    "factor ⟶ loc\n",
    "loc ⟶ id rest1\n",
    "rest1⟶ℇ\n",
    "rest6⟶ℇ\n",
    "rest5⟶ℇ\n",
    "rop_expr⟶ℇ\n",
    "rest4⟶ℇ\n",
    "rest1⟶ℇ\n",
    "rest6⟶ℇ\n",
    "rest5⟶ℇ\n",
    "rop_expr⟶ℇ\n",
    "rest4⟶ℇ\n",
    "stmt⟶loc = bool;\n",
    "loc ⟶ id rest1\n",
    "rest1⟶ℇ\n",
    "bool ⟶ equality\n",
    "equality ⟶rel rest4\n",
    "rel ⟶expr rop_expr\n",
    "expr ⟶ term rest5\n",
    "term ⟶ unary rest6\n",
    "unary ⟶factor\n",
    "factor ⟶ num\n",
    "rest6⟶ℇ\n",
    "rest5⟶ℇ\n",
    "rop_expr⟶ℇ\n",
    "rest4 ⟶ℇ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aodprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
